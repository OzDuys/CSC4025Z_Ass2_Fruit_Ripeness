{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd4b000",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Fruit Ripeness CNN (Colab + W&B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915dbec",
   "metadata": {},
   "source": [
    "This notebook extends the baseline CNN to run hyperparameter searches with [Weights & Biases](https://wandb.ai/). It is structured for Google Colab (GPU runtime) or local execution and logs richer metrics such as macro F1 and ROC-AUC to guide model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13819681",
   "metadata": {},
   "source": [
    "**Notebook outline**\n",
    "\n",
    "- Install dependencies (Colab-friendly)\n",
    "- Configure Kaggle API + dataset download\n",
    "- Define reusable data loaders, models, and training utilities\n",
    "- Launch single runs or W&B sweeps across hyperparameters and architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "!pip install -q kagglehub wandb torch torchvision torchaudio scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08648b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import contextlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import (\n",
    "    resnet18,\n",
    "    ResNet18_Weights,\n",
    "    mobilenet_v3_small,\n",
    "    MobileNet_V3_Small_Weights,\n",
    "    efficientnet_b0,\n",
    "    EfficientNet_B0_Weights,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from torch import amp\n",
    "except ImportError:  # Fallback for older PyTorch versions\n",
    "    from torch.cuda import amp  # type: ignore[attr-defined]\n",
    "\n",
    "try:\n",
    "    from google.colab import files  # type: ignore\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    files = None\n",
    "    IS_COLAB = False\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'fruit_ripeness_dataset'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on device: {DEVICE}')\n",
    "print(f'Project root: {PROJECT_ROOT}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kaggle_dir = Path.home() / '.kaggle'\n",
    "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "kaggle_json = kaggle_dir / 'kaggle.json'\n",
    "if not kaggle_json.exists():\n",
    "    if files is None:\n",
    "        raise FileNotFoundError(\n",
    "            'kaggle.json not found. Upload it in Colab or place it in ~/.kaggle/'\n",
    "        )\n",
    "    print('Upload your kaggle.json file (Account > Create New API Token).')\n",
    "    uploaded = files.upload()\n",
    "    if not uploaded:\n",
    "        raise ValueError('No files uploaded.')\n",
    "    name, data = next(iter(uploaded.items()))\n",
    "    if name != 'kaggle.json':\n",
    "        print(f\"Received '{name}'. Renaming to 'kaggle.json'.\")\n",
    "    kaggle_json.write_bytes(data)\n",
    "    print('kaggle.json uploaded.')\n",
    "else:\n",
    "    print('kaggle.json already present; skipping upload.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dded1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d594487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import zipfile\n",
    "import kagglehub\n",
    "\n",
    "DATASET_SLUG = 'leftin/fruit-ripeness-unripe-ripe-and-rotten'\n",
    "TARGET_DIR = DATA_ROOT\n",
    "FORCE_DOWNLOAD = False  # Set to True to refresh the dataset\n",
    "\n",
    "def iter_files(path: Path):\n",
    "    return [p for p in path.rglob('*') if p.is_file()]\n",
    "\n",
    "def copy_contents(src: Path, dst: Path) -> None:\n",
    "    files = iter_files(src)\n",
    "    if not files:\n",
    "        return\n",
    "    for file_path in tqdm(files, desc='Copying dataset files', unit='file'):\n",
    "        relative = file_path.relative_to(src)\n",
    "        target_path = dst / relative\n",
    "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(file_path, target_path)\n",
    "\n",
    "def extract_archives(path: Path) -> None:\n",
    "    zip_paths = list(path.rglob('*.zip'))\n",
    "    for zip_path in tqdm(zip_paths, desc='Extracting archives', unit='zip'):\n",
    "        out_dir = zip_path.with_suffix('')\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            for member in tqdm(zf.namelist(), desc=f'Extracting {zip_path.name}', leave=False, unit='file'):\n",
    "                zf.extract(member, out_dir)\n",
    "        zip_path.unlink()\n",
    "\n",
    "def find_split_dir(root: Path, name: str):\n",
    "    candidates = sorted([p for p in root.rglob(name) if p.is_dir()], key=lambda p: len(p.parts))\n",
    "    for candidate in candidates:\n",
    "        if any(candidate.glob('*/*')):\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "if TARGET_DIR.exists() and not FORCE_DOWNLOAD:\n",
    "    print(f'Dataset already present at {TARGET_DIR.resolve()}')\n",
    "else:\n",
    "    if TARGET_DIR.exists():\n",
    "        shutil.rmtree(TARGET_DIR)\n",
    "    TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'Downloading {DATASET_SLUG} with kagglehub â€¦')\n",
    "    downloaded_path = Path(kagglehub.dataset_download(DATASET_SLUG)).resolve()\n",
    "    print(f'Download complete: {downloaded_path}')\n",
    "    copy_contents(downloaded_path, TARGET_DIR)\n",
    "    extract_archives(TARGET_DIR)\n",
    "    print(f'Dataset extracted to {TARGET_DIR.resolve()}')\n",
    "\n",
    "TRAIN_DIR = find_split_dir(TARGET_DIR, 'train')\n",
    "TEST_DIR = find_split_dir(TARGET_DIR, 'test')\n",
    "if TRAIN_DIR is None or TEST_DIR is None:\n",
    "    raise RuntimeError(\"Expected 'train' and 'test' folders inside the dataset directory.\")\n",
    "\n",
    "print(f'Train directory: {TRAIN_DIR}')\n",
    "print(f'Test directory: {TEST_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f455905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_TRAIN_DATASET = ImageFolder(TRAIN_DIR, transform=None)\n",
    "BASE_TEST_DATASET = ImageFolder(TEST_DIR, transform=None)\n",
    "if BASE_TEST_DATASET.classes != BASE_TRAIN_DATASET.classes:\n",
    "    raise RuntimeError('Class labels differ between train and test directories.')\n",
    "CLASS_NAMES = BASE_TRAIN_DATASET.classes\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f'Classes: {CLASS_NAMES}')\n",
    "print(f'Train images: {len(BASE_TRAIN_DATASET)} | Test images: {len(BASE_TEST_DATASET)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8d948",
   "metadata": {},
   "source": [
    "**Metrics monitored during tuning**\n",
    "\n",
    "- `accuracy`: overall correctness for sanity checks.\n",
    "- `macro_f1`: treats each class equally, ideal when classes are imbalanced.\n",
    "- `weighted_f1`: accounts for class frequency while still penalising poor minority-class recall.\n",
    "- `balanced_accuracy`: average recall per class, highlighting skew.\n",
    "- `roc_auc_ovr`: one-vs-rest ROC AUC computed from predicted probabilities (logged when all classes appear in the split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ec517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WANDB_PROJECT = 'fruit-ripeness-cnn'\n",
    "WANDB_ENTITY = None  # Set to your team/user; None uses the default account\n",
    "WANDB_TAGS_BASE = ['fruit-ripeness', 'cnn', 'hyperparam-tuning']\n",
    "WANDB_NOTES = 'Hyperparameter sweeps for Assignment 2 CNN models.'\n",
    "\n",
    "DEFAULT_CONFIG = {\n",
    "    'seed': 42,\n",
    "    'image_size': 224,\n",
    "    'val_split': 0.15,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 15,\n",
    "    'learning_rate': 3e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'optimizer': 'adamw',\n",
    "    'architecture': 'simple_cnn',\n",
    "    'pretrained': False,\n",
    "    'dropout': 0.4,\n",
    "    'label_smoothing': 0.05,\n",
    "    'scheduler': 'cosine',\n",
    "    'min_lr': 1e-6,\n",
    "    'freeze_backbone': False,\n",
    "    'aug_hflip': True,\n",
    "    'aug_rotation': 10,\n",
    "    'aug_color_jitter': 0.2,\n",
    "    'aug_random_erasing': 0.0,\n",
    "    'use_amp': True,\n",
    "    'max_grad_norm': 2.0,\n",
    "    'patience': 4,\n",
    "    'log_model': False,\n",
    "    'wandb_mode': os.environ.get('WANDB_MODE', 'online'),\n",
    "}\n",
    "print('Default config keys:', list(DEFAULT_CONFIG.keys()))\n",
    "if os.environ.get('WANDB_API_KEY'):\n",
    "    try:\n",
    "        wandb.login()\n",
    "    except Exception as err:\n",
    "        print(f'W&B login failed: {err}')\n",
    "else:\n",
    "    print('Set WANDB_API_KEY or run wandb.login() to enable logging.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00687aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class SubsetWithTransform(Dataset):\n",
    "    def __init__(self, dataset: ImageFolder, indices, transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = list(indices)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def build_transforms(config, train: bool):\n",
    "    image_size = int(config['image_size'])\n",
    "    transform_list = [transforms.Resize((image_size, image_size))]\n",
    "    if train and config.get('aug_hflip', True):\n",
    "        transform_list.append(transforms.RandomHorizontalFlip())\n",
    "    rotation = float(config.get('aug_rotation', 0))\n",
    "    if train and rotation:\n",
    "        transform_list.append(transforms.RandomRotation(rotation))\n",
    "    jitter = float(config.get('aug_color_jitter', 0))\n",
    "    if train and jitter > 0:\n",
    "        transform_list.append(\n",
    "            transforms.ColorJitter(\n",
    "                brightness=jitter,\n",
    "                contrast=jitter,\n",
    "                saturation=min(1.0, jitter),\n",
    "                hue=min(0.5, jitter * 0.1),\n",
    "            )\n",
    "        )\n",
    "    transform_list.append(transforms.ToTensor())\n",
    "    transform_list.append(\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    )\n",
    "    erasing_p = float(config.get('aug_random_erasing', 0))\n",
    "    if train and erasing_p > 0:\n",
    "        transform_list.append(transforms.RandomErasing(p=erasing_p, value='random'))\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "def create_dataloaders(config):\n",
    "    val_split = float(config['val_split'])\n",
    "    batch_size = int(config['batch_size'])\n",
    "    generator = torch.Generator().manual_seed(int(config['seed']))\n",
    "\n",
    "    val_size = max(1, int(len(BASE_TRAIN_DATASET) * val_split))\n",
    "    train_size = len(BASE_TRAIN_DATASET) - val_size\n",
    "    train_subset, val_subset = random_split(\n",
    "        BASE_TRAIN_DATASET, [train_size, val_size], generator=generator\n",
    "    )\n",
    "\n",
    "    train_transforms = build_transforms(config, train=True)\n",
    "    eval_transforms = build_transforms(config, train=False)\n",
    "\n",
    "    train_dataset = SubsetWithTransform(BASE_TRAIN_DATASET, train_subset.indices, train_transforms)\n",
    "    val_dataset = SubsetWithTransform(BASE_TRAIN_DATASET, val_subset.indices, eval_transforms)\n",
    "    test_dataset = SubsetWithTransform(BASE_TEST_DATASET, range(len(BASE_TEST_DATASET)), eval_transforms)\n",
    "\n",
    "    num_workers = 0 if IS_COLAB else max(0, min(4, (os.cpu_count() or 1) - 1))\n",
    "    pin_memory = torch.cuda.is_available()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, CLASS_NAMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int, image_size: int = 224, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "        feature_dim = 128 * (image_size // 8) * (image_size // 8)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def build_model(config, num_classes):\n",
    "    arch = config['architecture']\n",
    "    dropout = float(config.get('dropout', 0.4))\n",
    "    pretrained = bool(config.get('pretrained', False))\n",
    "    freeze_backbone = bool(config.get('freeze_backbone', False))\n",
    "    image_size = int(config['image_size'])\n",
    "\n",
    "    if arch == 'simple_cnn':\n",
    "        model = SimpleCNN(num_classes=num_classes, image_size=image_size, dropout=dropout)\n",
    "    elif arch == 'resnet18':\n",
    "        weights = ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        model = resnet18(weights=weights)\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features, num_classes),\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "    elif arch == 'mobilenet_v3_small':\n",
    "        weights = MobileNet_V3_Small_Weights.DEFAULT if pretrained else None\n",
    "        model = mobilenet_v3_small(weights=weights)\n",
    "        if freeze_backbone:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[2] = nn.Dropout(p=dropout, inplace=True)\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "        if freeze_backbone:\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "    elif arch == 'efficientnet_b0':\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT if pretrained else None\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "        if freeze_backbone:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[0] = nn.Dropout(p=dropout, inplace=True)\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "        if freeze_backbone:\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(f'Unknown architecture: {arch}')\n",
    "\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def build_optimizer(model, config):\n",
    "    lr = float(config['learning_rate'])\n",
    "    weight_decay = float(config.get('weight_decay', 0.0))\n",
    "    optimizer_name = config.get('optimizer', 'adamw').lower()\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        momentum = float(config.get('momentum', 0.9))\n",
    "        nesterov = bool(config.get('nesterov', True))\n",
    "        optimizer = torch.optim.SGD(parameters, lr=lr, weight_decay=weight_decay, momentum=momentum, nesterov=nesterov)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(parameters, lr=lr, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "def build_scheduler(optimizer, config):\n",
    "    scheduler_name = config.get('scheduler', 'cosine').lower()\n",
    "    epochs = int(config['epochs'])\n",
    "    min_lr = float(config.get('min_lr', 1e-6))\n",
    "    if scheduler_name == 'cosine':\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, epochs), eta_min=min_lr)\n",
    "    if scheduler_name == 'plateau':\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, min_lr=min_lr)\n",
    "    return None\n",
    "\n",
    "def compute_metrics(y_true, y_probs):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_probs = np.asarray(y_probs)\n",
    "    y_pred = y_probs.argmax(axis=1)\n",
    "    metrics = {\n",
    "        'accuracy': float((y_pred == y_true).mean()),\n",
    "        'macro_f1': float(f1_score(y_true, y_pred, average='macro')),\n",
    "        'weighted_f1': float(f1_score(y_true, y_pred, average='weighted')),\n",
    "        'balanced_accuracy': float(balanced_accuracy_score(y_true, y_pred)),\n",
    "    }\n",
    "    try:\n",
    "        metrics['roc_auc_ovr'] = float(roc_auc_score(y_true, y_probs, multi_class='ovr'))\n",
    "    except ValueError:\n",
    "        metrics['roc_auc_ovr'] = float('nan')\n",
    "    return metrics, y_pred\n",
    "\n",
    "def autocast_context(enabled: bool):\n",
    "    if not enabled:\n",
    "        return contextlib.nullcontext()\n",
    "    try:\n",
    "        return amp.autocast(device_type=DEVICE.type, enabled=True)\n",
    "    except TypeError:\n",
    "        return amp.autocast(enabled=True)\n",
    "\n",
    "def create_grad_scaler(enabled: bool):\n",
    "    if not enabled:\n",
    "        return None\n",
    "    grad_scaler_cls = getattr(amp, 'GradScaler')\n",
    "    try:\n",
    "        return grad_scaler_cls(device_type=DEVICE.type, enabled=True)\n",
    "    except TypeError:\n",
    "        return grad_scaler_cls(enabled=True)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, config, epoch):\n",
    "    model.train()\n",
    "    use_amp = scaler is not None and scaler.is_enabled()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "    progress = tqdm(loader, desc=f'Train {epoch:02d}', leave=False)\n",
    "    for images, labels in progress:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast_context(use_amp):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        if scaler is not None and scaler.is_enabled():\n",
    "            scaler.scale(loss).backward()\n",
    "            if config.get('max_grad_norm', 0) > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if config.get('max_grad_norm', 0) > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        progress.set_postfix(loss=running_loss / total, acc=running_correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, criterion, config, split='Eval', epoch=None):\n",
    "    model.eval()\n",
    "    use_amp = config.get('use_amp', True) and DEVICE.type == 'cuda'\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    probs_buffer = []\n",
    "    labels_buffer = []\n",
    "    desc = f'{split} {epoch:02d}' if epoch is not None else split\n",
    "    progress = tqdm(loader, desc=desc, leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "            with autocast_context(use_amp):\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "            probs = torch.softmax(logits, dim=1).cpu()\n",
    "            labels_cpu = labels.cpu()\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "            probs_buffer.append(probs)\n",
    "            labels_buffer.append(labels_cpu)\n",
    "            preds = probs.argmax(dim=1)\n",
    "            batch_acc = (preds == labels_cpu).float().mean().item()\n",
    "            progress.set_postfix(loss=running_loss / total, acc=batch_acc)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    y_probs = torch.cat(probs_buffer).numpy()\n",
    "    y_true = torch.cat(labels_buffer).numpy()\n",
    "    metrics, y_pred = compute_metrics(y_true, y_probs)\n",
    "    return avg_loss, metrics, y_true, y_probs, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf12fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config=None, enable_wandb=True, run_name=None):\n",
    "    cfg = DEFAULT_CONFIG.copy()\n",
    "    extra_tags = WANDB_TAGS_BASE.copy()\n",
    "    notes = WANDB_NOTES\n",
    "    if config:\n",
    "        for key, value in config.items():\n",
    "            if key in cfg:\n",
    "                cfg[key] = value\n",
    "        if 'tags' in config:\n",
    "            tags = config['tags']\n",
    "            if isinstance(tags, (list, tuple)):\n",
    "                extra_tags.extend(tags)\n",
    "            else:\n",
    "                extra_tags.append(tags)\n",
    "        if 'notes' in config:\n",
    "            notes = f\"{WANDB_NOTES} | {config['notes']}\"\n",
    "\n",
    "    use_amp = cfg.get('use_amp', True) and DEVICE.type == 'cuda'\n",
    "    scaler = create_grad_scaler(use_amp)\n",
    "    wandb_mode = cfg.get('wandb_mode', 'online')\n",
    "    if not enable_wandb:\n",
    "        wandb_mode = 'disabled'\n",
    "\n",
    "    with wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        entity=WANDB_ENTITY,\n",
    "        config=cfg,\n",
    "        mode=wandb_mode,\n",
    "        job_type='tuning',\n",
    "        tags=extra_tags,\n",
    "        name=run_name,\n",
    "        notes=notes,\n",
    "    ) as run:\n",
    "        cfg_runtime = dict(run.config) if run is not None else cfg\n",
    "        seed_everything(int(cfg_runtime['seed']))\n",
    "        train_loader, val_loader, test_loader, class_names = create_dataloaders(cfg_runtime)\n",
    "        model = build_model(cfg_runtime, num_classes=len(class_names))\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=float(cfg_runtime.get('label_smoothing', 0.0)))\n",
    "        optimizer = build_optimizer(model, cfg_runtime)\n",
    "        scheduler = build_scheduler(optimizer, cfg_runtime)\n",
    "        epochs = int(cfg_runtime['epochs'])\n",
    "        best_metric = float('-inf')\n",
    "        best_state = None\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, scaler, cfg_runtime, epoch)\n",
    "            val_loss, val_metrics, y_true_val, y_probs_val, y_pred_val = evaluate(model, val_loader, criterion, cfg_runtime, split='Validation', epoch=epoch)\n",
    "\n",
    "            if scheduler:\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_metrics['macro_f1'])\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            log_payload = {\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'train_accuracy': train_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            }\n",
    "            for key, value in val_metrics.items():\n",
    "                log_payload[f'val_{key}'] = value\n",
    "            wandb.log(log_payload)\n",
    "\n",
    "            if val_metrics['macro_f1'] > best_metric:\n",
    "                best_metric = val_metrics['macro_f1']\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "                epochs_without_improvement = 0\n",
    "                wandb.log({'best_val_macro_f1': best_metric}, commit=False)\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "\n",
    "            if cfg_runtime.get('patience', 0) and epochs_without_improvement >= int(cfg_runtime['patience']):\n",
    "                print(f'Early stopping at epoch {epoch} (best val macro F1: {best_metric:.4f})')\n",
    "                break\n",
    "\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "\n",
    "        test_loss, test_metrics, y_true_test, y_probs_test, y_pred_test = evaluate(model, test_loader, criterion, cfg_runtime, split='Test')\n",
    "\n",
    "        test_log = {'test_loss': test_loss}\n",
    "        for key, value in test_metrics.items():\n",
    "            test_log[f'test_{key}'] = value\n",
    "        wandb.log(test_log)\n",
    "\n",
    "        try:\n",
    "            cm_plot = wandb.plot.confusion_matrix(y_true=y_true_test, preds=y_pred_test, class_names=class_names)\n",
    "            wandb.log({'test_confusion_matrix': cm_plot})\n",
    "        except Exception as err:\n",
    "            print(f'Confusion matrix not logged: {err}')\n",
    "\n",
    "        try:\n",
    "            roc_plot = wandb.plot.roc_curve(y_true_test, y_probs_test, labels=class_names)\n",
    "            wandb.log({'test_roc_curve': roc_plot})\n",
    "        except Exception as err:\n",
    "            print(f'ROC curve not logged: {err}')\n",
    "\n",
    "        report = classification_report(y_true_test, y_pred_test, target_names=class_names, output_dict=True)\n",
    "        report_table = wandb.Table(columns=['class', 'precision', 'recall', 'f1', 'support'])\n",
    "        for class_name in class_names:\n",
    "            stats = report[class_name]\n",
    "            report_table.add_data(class_name, float(stats['precision']), float(stats['recall']), float(stats['f1-score']), int(stats['support']))\n",
    "        weighted_stats = report['weighted avg']\n",
    "        report_table.add_data('weighted avg', float(weighted_stats['precision']), float(weighted_stats['recall']), float(weighted_stats['f1-score']), int(weighted_stats['support']))\n",
    "        wandb.log({'test_classification_report': report_table})\n",
    "\n",
    "        if cfg_runtime.get('log_model', False) and run is not None:\n",
    "            ckpt_dir = PROJECT_ROOT / 'checkpoints'\n",
    "            ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "            ckpt_path = ckpt_dir / f\"{run.name or run.id}_best.pt\"\n",
    "            torch.save({'model_state_dict': best_state, 'config': cfg_runtime, 'class_names': class_names}, ckpt_path)\n",
    "            artifact = wandb.Artifact(name=f\"{run.name or run.id}-model\", type='model')\n",
    "            artifact.add_file(ckpt_path)\n",
    "            run.log_artifact(artifact)\n",
    "            print(f'Saved best model checkpoint to {ckpt_path}')\n",
    "\n",
    "        print('Test metrics:')\n",
    "        for key, value in test_metrics.items():\n",
    "            print(f'  {key}: {value:.4f}')\n",
    "        return test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWEEP_CONFIG = {\n",
    "    'name': 'cnn-architecture-hparam-search',\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'val_macro_f1', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'architecture': {'values': ['simple_cnn', 'resnet18', 'mobilenet_v3_small', 'efficientnet_b0']},\n",
    "        'pretrained': {'values': [True, False]},\n",
    "        'freeze_backbone': {'values': [True, False]},\n",
    "        'learning_rate': {'distribution': 'log_uniform_values', 'min': 1e-5, 'max': 3e-3},\n",
    "        'weight_decay': {'distribution': 'log_uniform_values', 'min': 1e-6, 'max': 1e-2},\n",
    "        'batch_size': {'values': [32, 48, 64]},\n",
    "        'dropout': {'min': 0.1, 'max': 0.6},\n",
    "        'aug_color_jitter': {'values': [0.0, 0.15, 0.3]},\n",
    "        'aug_random_erasing': {'values': [0.0, 0.1, 0.25]},\n",
    "        'optimizer': {'values': ['adamw', 'adam', 'sgd']},\n",
    "    },\n",
    "}\n",
    "print('Sweep ready. Primary metric:', SWEEP_CONFIG['metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sweep_entry(config=None):\n",
    "    return run_experiment(config=config, enable_wandb=True)\n",
    "\n",
    "print('To launch: sweep_id = wandb.sweep(SWEEP_CONFIG, project=WANDB_PROJECT, entity=WANDB_ENTITY)')\n",
    "print('Then run: wandb.agent(sweep_id, sweep_entry, count=NUM_RUNS)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c891845",
   "metadata": {},
   "source": [
    "**Quick smoke test (optional)**\n",
    "\n",
    "Toggle the cell below if you want to run a fast sanity check without logging to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219523b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:  # Set to True for a quick offline run\n",
    "    debug_config = {**DEFAULT_CONFIG, 'epochs': 2, 'batch_size': 16, 'architecture': 'simple_cnn', 'use_amp': False}\n",
    "    run_experiment(config=debug_config, enable_wandb=False, run_name='debug-run')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe480d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example sweep launch (uncomment to execute)\n",
    "# sweep_id = wandb.sweep(SWEEP_CONFIG, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
    "# wandb.agent(sweep_id, function=sweep_entry, count=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}