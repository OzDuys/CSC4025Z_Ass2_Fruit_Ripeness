{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 1.4: Extended Training + LR Scheduler\n",
        "\n",
        "**Based on Baseline Fruit Ripeness Classifier**\n",
        "\n",
        "## Changes from Baseline:\n",
        "- ‚úÖ NUM_EPOCHS: 5 ‚Üí 40 (extended training)\n",
        "- ‚úÖ Added Learning Rate Scheduler (ReduceLROnPlateau)\n",
        "- ‚úÖ Enhanced visualization and tracking\n",
        "\n",
        "## How to Get Your Kaggle API Token:\n",
        "1. Go to https://www.kaggle.com/\n",
        "2. Click your profile picture (top right) ‚Üí **Settings**\n",
        "3. Scroll to **API** section  \n",
        "4. Click **\"Create New Token\"**\n",
        "5. Download `kaggle.json`\n",
        "6. Upload it when prompted in Step 3 below\n",
        "\n",
        "---\n",
        "\n",
        "Quick-start notebook tuned for Google Colab GPU usage.\n",
        "\n",
        "1. Install dependencies.\n",
        "2. Upload your `kaggle.json` when prompted.\n",
        "3. Download and prepare the dataset (handled below).\n",
        "4. Run the training and evaluation cells.\n",
        "\n",
        "You can also run this locally; skip the Kaggle upload cell if your credentials are already configured."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies\n",
        "Run this cell once per Colab session to install PyTorch, Kaggle, and analysis libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q kagglehub torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q numpy pandas scikit-learn matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Configure the Runtime\n",
        "Imports the packages needed for data handling, modelling, and plotting, then reports the active device.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Torch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure Kaggle Credentials\n",
        "Upload your Kaggle API token so the dataset can be downloaded automatically. The next cell also fixes the token file permissions required by Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290e9683",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    files = None\n",
        "    IS_COLAB = False\n",
        "\n",
        "kaggle_dir = Path.home() / \".kaggle\"\n",
        "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "kaggle_json = kaggle_dir / \"kaggle.json\"\n",
        "if not kaggle_json.exists():\n",
        "    if files is None:\n",
        "        raise FileNotFoundError(\n",
        "            \"kaggle.json not found. Upload it in Colab or place it in ~/.kaggle/\"\n",
        "        )\n",
        "    print(\"Upload your kaggle.json file (Account > Create New API Token).\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise ValueError(\"No files uploaded.\")\n",
        "    if \"kaggle.json\" in uploaded:\n",
        "        data = uploaded[\"kaggle.json\"]\n",
        "    else:\n",
        "        filename, data = next(iter(uploaded.items()))\n",
        "        print(f\"Received '{filename}'. Renaming to 'kaggle.json'.\")\n",
        "    kaggle_json.write_bytes(data)\n",
        "    print(\"kaggle.json uploaded.\")\n",
        "else:\n",
        "    print(\"kaggle.json already present; skipping upload.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195afb07",
      "metadata": {},
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287446d0",
      "metadata": {},
      "source": [
        "## 4. Download and Prepare the Dataset\n",
        "Downloads the Kaggle dataset with `kagglehub`, extracts archives, and locates the train/test directories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f1f112",
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "DATASET_SLUG = \"leftin/fruit-ripeness-unripe-ripe-and-rotten\"\n",
        "TARGET_DIR = Path(\"data/fruit_ripeness_dataset\")\n",
        "FORCE_DOWNLOAD = False  # Set to True to refresh the dataset\n",
        "\n",
        "\n",
        "def iter_files(path: Path):\n",
        "    return [p for p in path.rglob('*') if p.is_file()]\n",
        "\n",
        "\n",
        "def copy_contents(src: Path, dst: Path) -> None:\n",
        "    files = iter_files(src)\n",
        "    if not files:\n",
        "        return\n",
        "    for file_path in tqdm(files, desc=\"Copying dataset files\", unit=\"file\"):\n",
        "        relative = file_path.relative_to(src)\n",
        "        target = dst / relative\n",
        "        target.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(file_path, target)\n",
        "\n",
        "\n",
        "def extract_archives(path: Path) -> None:\n",
        "    zip_files = list(path.rglob(\"*.zip\"))\n",
        "    for zip_path in tqdm(zip_files, desc=\"Extracting archives\", unit=\"zip\"):\n",
        "        extract_dir = zip_path.with_suffix(\"\")\n",
        "        extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "            members = zf.namelist()\n",
        "            for member in tqdm(members, desc=f\"Extracting {zip_path.name}\", leave=False, unit=\"file\"):\n",
        "                zf.extract(member, extract_dir)\n",
        "        zip_path.unlink()\n",
        "\n",
        "\n",
        "def find_split_dir(root: Path, name: str):\n",
        "    candidates = sorted(\n",
        "        [p for p in root.rglob(name) if p.is_dir()],\n",
        "        key=lambda p: len(p.parts),\n",
        "    )\n",
        "    for candidate in candidates:\n",
        "        if any(candidate.glob(\"*/*\")):\n",
        "            return candidate\n",
        "    return None\n",
        "\n",
        "\n",
        "if TARGET_DIR.exists() and not FORCE_DOWNLOAD:\n",
        "    print(f\"Dataset already present at {TARGET_DIR.resolve()}\\nSet FORCE_DOWNLOAD=True to re-download.\")\n",
        "else:\n",
        "    if TARGET_DIR.exists() and FORCE_DOWNLOAD:\n",
        "        shutil.rmtree(TARGET_DIR)\n",
        "    TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Downloading {DATASET_SLUG} with kagglehub ...\")\n",
        "    downloaded_path = Path(kagglehub.dataset_download(DATASET_SLUG)).resolve()\n",
        "    print(f\"Download complete: {downloaded_path}\")\n",
        "    copy_contents(downloaded_path, TARGET_DIR)\n",
        "    extract_archives(TARGET_DIR)\n",
        "    print(f\"Dataset extracted to {TARGET_DIR.resolve()}\")\n",
        "\n",
        "TRAIN_DIR = find_split_dir(TARGET_DIR, \"train\")\n",
        "TEST_DIR = find_split_dir(TARGET_DIR, \"test\")\n",
        "\n",
        "if TRAIN_DIR is None:\n",
        "    raise RuntimeError(\n",
        "        f\"Could not locate a 'train' directory inside {TARGET_DIR.resolve()}\"\n",
        "    )\n",
        "\n",
        "print(f\"Using train directory: {TRAIN_DIR}\")\n",
        "if TEST_DIR is None:\n",
        "    raise RuntimeError(\n",
        "        f\"Could not locate a 'test' directory inside {TARGET_DIR.resolve()}\"\n",
        "    )\n",
        "print(f\"Using test directory: {TEST_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e724d5",
      "metadata": {},
      "source": [
        "## 5. Set Hyperparameters\n",
        "\n",
        "**üî¨ EXPERIMENT 1.4 CONFIGURATION**\n",
        "\n",
        "Changes from baseline:\n",
        "- NUM_EPOCHS: 5 ‚Üí **40**\n",
        "- Added **Learning Rate Scheduler** (ReduceLROnPlateau)\n",
        "\n",
        "Central place to adjust random seed, batch size, image size, and training duration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2bd343d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# EXPERIMENT 1.4 CONFIGURATION\n",
        "# ============================================================\n",
        "EXPERIMENT_NAME = \"Exp_1.4_Extended_Training_LR_Scheduler\"\n",
        "\n",
        "SEED = 42\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 40  # üî¨ CHANGED: Was 5 ‚Üí now 40\n",
        "VAL_SPLIT = 0.15\n",
        "IMAGE_SIZE = 224\n",
        "LEARNING_RATE = 1e-3  # 0.001\n",
        "\n",
        "# üî¨ NEW: Learning Rate Scheduler Configuration\n",
        "USE_LR_SCHEDULER = True\n",
        "LR_SCHEDULER_PATIENCE = 3  # Reduce LR after 3 epochs of no improvement\n",
        "LR_SCHEDULER_FACTOR = 0.5  # Reduce LR by half\n",
        "LR_SCHEDULER_MIN_LR = 1e-6  # Minimum learning rate\n",
        "\n",
        "\n",
        "def set_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7479366",
      "metadata": {},
      "source": [
        "## 6. Build Datasets and DataLoaders\n",
        "Creates stratified training/validation/test splits, applies transforms, and prepares PyTorch data loaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507b96ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "full_dataset = ImageFolder(TRAIN_DIR, transform=None)\n",
        "if len(full_dataset) == 0:\n",
        "    raise RuntimeError(\"ImageFolder found no images in the training directory.\")\n",
        "\n",
        "class_names = full_dataset.classes\n",
        "print(f\"Detected classes: {class_names}\")\n",
        "\n",
        "val_size = max(1, int(len(full_dataset) * VAL_SPLIT))\n",
        "remaining_for_train = len(full_dataset) - val_size\n",
        "\n",
        "generator = torch.Generator().manual_seed(SEED)\n",
        "train_subset, val_subset = random_split(\n",
        "    full_dataset,\n",
        "    [remaining_for_train, val_size],\n",
        "    generator=generator,\n",
        ")\n",
        "\n",
        "raw_test_dataset = ImageFolder(TEST_DIR, transform=None)\n",
        "if raw_test_dataset.classes != class_names:\n",
        "    raise RuntimeError(\"Class labels differ between train and test directories.\")\n",
        "test_indices = range(len(raw_test_dataset))\n",
        "\n",
        "\n",
        "class SubsetWithTransform(Dataset):\n",
        "    def __init__(self, dataset: ImageFolder, indices, transform):\n",
        "        self.dataset = dataset\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "eval_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = SubsetWithTransform(full_dataset, train_subset.indices, train_transforms)\n",
        "val_dataset = SubsetWithTransform(full_dataset, val_subset.indices, eval_transforms)\n",
        "test_dataset = SubsetWithTransform(raw_test_dataset, test_indices, eval_transforms)\n",
        "\n",
        "num_workers = 0 if IS_COLAB else min(2, (os.cpu_count() or 1) - 1 if (os.cpu_count() or 1) > 1 else 0)\n",
        "num_workers = max(num_workers, 0)\n",
        "pin_memory = torch.cuda.is_available()\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "print(\n",
        "    f\"Data sizes -> train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define the Baseline CNN\n",
        "A lightweight convolutional network used as the initial benchmark model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * (IMAGE_SIZE // 8) * (IMAGE_SIZE // 8), 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = SimpleCNN(num_classes=len(class_names)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model parameters: {total_params / 1e6:.2f}M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_init",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleCNN(num_classes=len(class_names)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# üî¨ NEW: Add Learning Rate Scheduler\n",
        "if USE_LR_SCHEDULER:\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=LR_SCHEDULER_FACTOR,\n",
        "        patience=LR_SCHEDULER_PATIENCE,\n",
        "        verbose=True,\n",
        "        min_lr=LR_SCHEDULER_MIN_LR\n",
        "    )\n",
        "    print(\"‚úÖ Learning Rate Scheduler: ReduceLROnPlateau\")\n",
        "    print(f\"   Patience: {LR_SCHEDULER_PATIENCE} epochs\")\n",
        "    print(f\"   Factor: {LR_SCHEDULER_FACTOR}x\")\n",
        "    print(f\"   Min LR: {LR_SCHEDULER_MIN_LR}\")\n",
        "else:\n",
        "    scheduler = None\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nModel: SimpleCNN\")\n",
        "print(f\"Parameters: {total_params / 1e6:.2f}M\")\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"EXPERIMENT: {EXPERIMENT_NAME}\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Epochs:        {NUM_EPOCHS}\")\n",
        "print(f\"Batch Size:    {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"LR Scheduler:  {'Yes' if USE_LR_SCHEDULER else 'No'}\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Define Training Utilities\n",
        "Helper functions for training and evaluation, including tqdm progress bars for batch-level insight.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device, epoch=None, total_epochs=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    desc = \"Training\" if epoch is None or total_epochs is None else f\"Train {epoch:02d}/{total_epochs:02d}\"\n",
        "    progress = tqdm(loader, desc=desc, leave=False, unit=\"batch\")\n",
        "\n",
        "    for images, labels in progress:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
        "        total += images.size(0)\n",
        "\n",
        "        if total:\n",
        "            progress.set_postfix(\n",
        "                loss=running_loss / total,\n",
        "                acc=running_correct / total,\n",
        "            )\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device, split=\"Eval\", epoch=None, total_epochs=None):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if epoch is None or total_epochs is None:\n",
        "        desc = split\n",
        "    else:\n",
        "        desc = f\"{split} {epoch:02d}/{total_epochs:02d}\"\n",
        "    progress = tqdm(loader, desc=desc, leave=False, unit=\"batch\")\n",
        "\n",
        "    for images, labels in progress:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_correct += (logits.argmax(dim=1) == labels).sum().item()\n",
        "        total += images.size(0)\n",
        "\n",
        "        if total:\n",
        "            progress.set_postfix(\n",
        "                loss=running_loss / total,\n",
        "                acc=running_correct / total,\n",
        "            )\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Run the Training Loop\n",
        "\n",
        "üî¨ **Modified**: Added LR scheduler step and enhanced tracking.\n",
        "\n",
        "Executes the epoch loop with tqdm progress bars to monitor loss and accuracy updates in real time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": [], \"learning_rates\": []}\n",
        "best_val_acc = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Track current LR\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    history[\"learning_rates\"].append(current_lr)\n",
        "    \n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, device, epoch=epoch, total_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        model, val_loader, criterion, device, split=\"Validation\", epoch=epoch, total_epochs=NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    \n",
        "    # Track best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    # üî¨ NEW: Step the learning rate scheduler\n",
        "    if USE_LR_SCHEDULER and scheduler is not None:\n",
        "        old_lr = current_lr\n",
        "        scheduler.step(val_loss)\n",
        "        new_lr = optimizer.param_groups[0]['lr']\n",
        "        if new_lr != old_lr:\n",
        "            print(f\"   üìâ LR Reduced: {old_lr:.2e} ‚Üí {new_lr:.2e}\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d}/{NUM_EPOCHS} | \"\n",
        "        f\"train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} | \"\n",
        "        f\"val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f}\"\n",
        "        + (\" ‚≠ê\" if epoch == best_epoch else \"\")\n",
        "    )\n",
        "\n",
        "print(f\"\\nTraining complete! Best val acc: {best_val_acc:.4f} at epoch {best_epoch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9ab19c",
      "metadata": {},
      "source": [
        "## 10. Visualise Training Curves\n",
        "\n",
        "üî¨ **Enhanced**: Added learning rate schedule and train/val gap plots.\n",
        "\n",
        "Plots loss and accuracy so you can inspect learning behaviour.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644c6c0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_range = range(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, history[\"train_loss\"], 'b-', label=\"Train\", linewidth=2)\n",
        "plt.plot(epochs_range, history[\"val_loss\"], 'r-', label=\"Validation\", linewidth=2)\n",
        "plt.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.5, label=f'Best: Epoch {best_epoch}')\n",
        "plt.title(\"Loss\", fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Cross-entropy\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, history[\"train_acc\"], 'b-', label=\"Train\", linewidth=2)\n",
        "plt.plot(epochs_range, history[\"val_acc\"], 'r-', label=\"Validation\", linewidth=2)\n",
        "plt.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.5, label=f'Best: Epoch {best_epoch}')\n",
        "plt.title(\"Accuracy\", fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Train/Val gap (overfitting indicator)\n",
        "plt.subplot(2, 2, 3)\n",
        "acc_gap = np.array(history[\"train_acc\"]) - np.array(history[\"val_acc\"])\n",
        "plt.plot(epochs_range, acc_gap, 'purple', linewidth=2)\n",
        "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "plt.fill_between(epochs_range, acc_gap, 0, alpha=0.3, color='purple')\n",
        "plt.title(\"Train/Val Gap (Overfitting Indicator)\", fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Gap\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.text(0.5, 0.95, f'Final: {acc_gap[-1]:.3f}', transform=plt.gca().transAxes,\n",
        "         ha='center', va='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Learning rate schedule\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs_range, history[\"learning_rates\"], 'orange', linewidth=2, marker='o', markersize=3)\n",
        "plt.title(\"Learning Rate Schedule\", fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.yscale('log')\n",
        "plt.grid(alpha=0.3, which='both')\n",
        "\n",
        "plt.suptitle(EXPERIMENT_NAME, fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Best Val Accuracy:  {max(history['val_acc']):.4f} at Epoch {np.argmax(history['val_acc'])+1}\")\n",
        "print(f\"Final Train Acc:    {history['train_acc'][-1]:.4f}\")\n",
        "print(f\"Final Val Acc:      {history['val_acc'][-1]:.4f}\")\n",
        "print(f\"Train/Val Gap:      {history['train_acc'][-1] - history['val_acc'][-1]:.4f}\")\n",
        "print(f\"Final LR:           {history['learning_rates'][-1]:.2e}\")\n",
        "print(f\"LR Reductions:      {len(set(history['learning_rates']))-1}\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6944a839",
      "metadata": {},
      "source": [
        "## 11. Evaluate on the Test Set\n",
        "Reports final performance using the held-out split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea4c768",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device, split=\"Test\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b94edf",
      "metadata": {},
      "source": [
        "## 12. (Optional) Save the Trained Model\n",
        "\n",
        "Toggle this to persist the model weights for reuse or submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_MODEL = False  # Switch to True to persist the trained weights\n",
        "\n",
        "if SAVE_MODEL:\n",
        "    checkpoint_dir = Path(\"checkpoints\")\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    checkpoint_path = checkpoint_dir / \"baseline_cnn.pt\"\n",
        "    torch.save({\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"class_names\": class_names,\n",
        "        \"image_size\": IMAGE_SIZE,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Saved checkpoint to {checkpoint_path.resolve()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
